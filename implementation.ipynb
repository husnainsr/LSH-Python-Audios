{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1be09627-3f57-4efc-8e00-10d7d0e6fc31",
   "metadata": {},
   "source": [
    "# Locality Sensitive Hashing for audio identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0dd45a-b39f-402b-bc1f-82cb8a783663",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "a75445ab-9123-463f-984b-0e16cf9496e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm,trange\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c26f07-8d28-4bac-8dca-7f7ab4510f9c",
   "metadata": {},
   "source": [
    "# This Function is used to extract MFCC of Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "79b76376-684e-431c-a14b-d56397447f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(path):\n",
    "    audio,sr =librosa.load(path)\n",
    "    mfccs=(librosa.feature.mfcc(y=audio, sr=sr))\n",
    "    mean=np.mean(mfccs,axis=1)\n",
    "    std=np.std(mfccs,axis=1)\n",
    "    mfcc_feature=(np.concatenate([mean, std]))\n",
    "    threshold = np.median(mfcc_feature)\n",
    "    bin_mfcc = (mfcc_feature > threshold).astype(int)\n",
    "    return bin_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341a99a-4581-42d7-b0d5-535a86b51d0c",
   "metadata": {},
   "source": [
    "# Random Permutation is genrated through this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "4dace27c-a9aa-4743-b4cc-1319150ce50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_random_perm(mfcc_length,number_permutation):\n",
    "    random_permutation=[]\n",
    "    number_permutation=number_permutation\n",
    "    mfcc_length=40\n",
    "    for i in range(0,number_permutation):   \n",
    "        check=True\n",
    "        while(check):\n",
    "            temp=np.random.permutation(mfcc_length)\n",
    "            if len(random_permutation)>0:\n",
    "                for j in range(0,len(random_permutation)):\n",
    "                    if(temp.all()==random_permutation[j].all()):\n",
    "                        check=False\n",
    "                        break\n",
    "                if(check==False):\n",
    "                    check=True\n",
    "                break\n",
    "            else:\n",
    "                break\n",
    "        random_permutation.append(temp)\n",
    "    return random_permutation\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc199d-5a07-4c74-bf36-67d60206ab75",
   "metadata": {},
   "source": [
    "# Genrate Hash takes MFCC and Permutation and return minimum Values from HashTable where 1 is peresent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "51e0997b-5cff-473b-8686-f00438927fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_hash(mfcc,random_permutation,number_permutation):\n",
    "    hash_signature=[]\n",
    "    for i in range(0,number_permutation):\n",
    "        index=np.where(mfcc== 1)\n",
    "        values = np.take(random_permutation[i],index)\n",
    "        min_value = np.min(values)\n",
    "        hash_signature.append(min_value)\n",
    "    return hash_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8d205-a20b-413c-801d-4bf4e9dfca14",
   "metadata": {},
   "source": [
    "# This buckets Function Divide the Hash Signature into Buckets and Assign the key item to value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "e736eddf-8e56-48a4-a4ea-165f0ce69a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buckets(LSH_table,hash_feature,fileName):\n",
    "    for i in range(0, len(hash_feature), 4):\n",
    "        # Sum the next 5 values in the array list\n",
    "        sum_ = sum(hash_feature[i:i+4])\n",
    "        current_values = LSH_table.get(sum_)  # retrieve the current values associated with the key \n",
    "        if current_values is None:\n",
    "            LSH_table[sum_] = fileName  # add a new key-value pair if the key does not exist\n",
    "        else:\n",
    "            current_values=current_values+\",\"+fileName\n",
    "            LSH_table[sum_]= current_values  # update the values associated with the key 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104d3c7-1a03-445f-a8d7-8ee6b5f54f56",
   "metadata": {},
   "source": [
    "# Querry Function Take Audio and threshold value to check along side stored values in LSH_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "c1d9f3ee-6f6e-4d97-9adb-9a51374774b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(audio,threshold,random_permutation,number_permutation,LSH_table,hashing_dict):\n",
    "    mfcc=extract_mfcc(audio) #querry mfcc\n",
    "    queryHash_feature=genrate_hash(mfcc,random_permutation,number_permutation) #querry hash is genrated\n",
    "    # print(queryHash_feature)\n",
    "    keys=[] \n",
    "    for i in range(0, len(queryHash_feature), 4):#this will sum next values\n",
    "        # Sum the next 5 values in the array list \n",
    "        sum_ = sum(queryHash_feature[i:i+4])\n",
    "        keys.append(sum_)\n",
    "    # print(keys)\n",
    "    AllFiles=[]\n",
    "    for i in range(0,len(keys)):  #this will extract all the key items and genrate unqiue files\n",
    "        if LSH_table.get(keys[i]) is None:\n",
    "            continue\n",
    "        files=LSH_table.get(keys[i]).split(\",\")\n",
    "        if len(files)>0:\n",
    "            for j in range(0,len(files)):\n",
    "                AllFiles.append(files[j])\n",
    "    uniqueFiles = list(set(AllFiles))\n",
    "    similarites={}\n",
    "    # threshold=0\n",
    "    for i in uniqueFiles:\n",
    "        dataBaseAudio_Hash=hashing_dict.get(i)\n",
    "        counter=0\n",
    "        for j in range(0,len(queryHash_feature)):\n",
    "            if(dataBaseAudio_Hash[j]==queryHash_feature[j]):\n",
    "                counter+=1\n",
    "        jaccardSimilarity=counter/20\n",
    "        if jaccardSimilarity>=threshold:\n",
    "            similarites[i]=jaccardSimilarity\n",
    "    max_key = max(similarites.items(), key=lambda x: x[1])[0]    \n",
    "    # print(similarites)\n",
    "    # print(\"Nearest Audio could be: \",max_key,\" with Jaccard Similarity \",similarites.get(max_key))\n",
    "    r=printAnswer(similarites)\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "a78788aa-bb20-4e37-9d8e-79a534c3ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAnswer(dic):\n",
    "    final_output=[]\n",
    "    if len(dic)!=0:\n",
    "        k=[]\n",
    "        val=[]\n",
    "        for key, value in sorted(dic.items(), key=lambda x: x[1],reverse=True):\n",
    "            k.append(key)\n",
    "            val.append(value)\n",
    "        s=\"Nearest Audio could be \"+str(k[0])+\" with Jaccard Similarity \"+ str(val[0]*100)+\"%\"\n",
    "        final_output.append(s)\n",
    "        # print(\"Nearest Audio could be: \",k[0],\" with Jaccard Similarity \",val[0])\n",
    "        s='------------------------------------------------------------------'\n",
    "        final_output.append(s)\n",
    "        # print('------------------------------------------------------------------')\n",
    "        if(len(k)>=2):\n",
    "            s=\"You Will Also Like these Audios: \",str(k[1]),\" and \"+str(k[2])\n",
    "            final_output.append(s)\n",
    "            # print(\"You Will Also Like these Audios: \",k[1],\" and \",k[2])\n",
    "        elif(len(k)>1):\n",
    "            s=\"You Will Also Like these Audio: \",str(k[1])\n",
    "            final_output.append(s)\n",
    "            # print(\"You Will Also Like these Audio: \",k[1])\n",
    "        else:\n",
    "            s='You Have Unique Taste Try this: 002096.mp3'\n",
    "            final_output.append(s)\n",
    "    else:\n",
    "        s='There is no Audio Matched Try changing the Threshold Value'\n",
    "        final_output.append(s)\n",
    "    return final_output\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb55441-d392-4efe-9b00-a4d6eedc198a",
   "metadata": {},
   "source": [
    "# Int Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "8b30ea42-a115-49fc-9251-346f602f1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "mfcc_length=40 #1Demensional\n",
    "number_permutation=20  #how many permutation columns are required\n",
    "LSH_table={}\n",
    "hashing_dict={}\n",
    "random_permutation=[] #this will store the random permutation\n",
    "\n",
    "#Genrate random_permutation list first and pickle it\n",
    "# random_permutation=genrate_random_perm(mfcc_length,number_permutation)\n",
    "# # Open a file for writing in binary mode\n",
    "# with open('random_perm.pickle', 'wb') as file:\n",
    "#     pickle.dump(random_permutation, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "8dc55407-ced9-4c7a-b78e-1361e369a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the file for reading in binary mode\n",
    "with open('random_perm.pickle', 'rb') as file:\n",
    "    random_permutation = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63edb-4326-4f21-a975-8c9d32fdbae3",
   "metadata": {},
   "source": [
    "# This function added all Audios in LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce065c8-e4f1-4dc3-9f7f-3652158babbe",
   "metadata": {},
   "source": [
    "Before Running Below Tab make sure you have audioMFCC.csv file in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "5fc5c0e2-6bfd-4c67-a4a7-f83dac80aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns=np.arange(0,41)\n",
    "df=pd.read_csv(\"audioMFCC.csv\",names=columns)\n",
    "for i in range(0,len(df.index)):\n",
    "    audios=df.iloc[i][1:]\n",
    "    threshold = np.median(audios)\n",
    "    bin_mfcc = (audios > threshold).astype(int)\n",
    "    binary_audios=bin_mfcc\n",
    "    hash_feature=genrate_hash(binary_audios,random_permutation,number_permutation)\n",
    "    hashing_dict[df.iloc[i,0]]=hash_feature\n",
    "    buckets(LSH_table,hash_feature,df.iloc[i,0],n_rows,n_bands)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "c5ce4255-0474-4843-a932-2a91350fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file for writing in binary mode\n",
    "with open('LSH_table.pickle', 'wb') as file:\n",
    "    pickle.dump(LSH_table, file)\n",
    "with open('hashing_dict.pickle', 'wb') as file:\n",
    "    pickle.dump(hashing_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "bfb3b583-e691-4e71-9cc3-2799d6ef8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file for reading in binary mode\n",
    "with open('LSH_table.pickle', 'rb') as file:\n",
    "    LSH_table = pickle.load(file)\n",
    "with open('hashing_dict.pickle', 'rb') as file:\n",
    "    hashing_dict = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5c663-f62b-4e56-8d35-a4901dfdb899",
   "metadata": {},
   "source": [
    "# This is Query Method where you only have to provide Test Audio Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "d2ea2e9f-5b6d-4746-b6a4-6704b2906282",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.9  #Jaccard Similarity Threshold to check similarity between test audio and others\n",
    "q=query(audio_files[2],threshold,random_permutation,number_permutation,LSH_table,hashing_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
